# ğŸ“± How Offline AI Works in EduLite - Complete Guide

## ğŸ¯ Quick Answer to Your Questions

| Question | Answer |
|----------|--------|
| **Do I need to download the model?** | Yes, users download models on first launch (~700 MB - 2 GB) |
| **Do I need Ollama?** | âŒ No! llama.rn runs directly on the phone's CPU/GPU |
| **Does the app include the model?** | âŒ No, models are too large. Users download separately |
| **How does it work offline?** | Models are stored on device, run 100% locally |
| **What about when I share the APK?** | User downloads models on first launch over WiFi |

---

## ğŸ—ï¸ Architecture: How It Actually Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     YOUR MOBILE DEVICE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    MasterJi App                             â”‚ â”‚
â”‚  â”‚                    (~50 MB installed)                       â”‚ â”‚
â”‚  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚              llama.rn Library                        â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  (React Native binding for llama.cpp)                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Loads GGUF model files from storage               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Uses phone's CPU for inference                    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Uses Metal (iOS) or OpenCL (Android) for GPU      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ 100% on-device, no internet needed                â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                          â”‚                                  â”‚ â”‚
â”‚  â”‚                          â–¼                                  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚          Local Storage (Phone's Storage)             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  ğŸ“ /data/data/com.edulite.masterji/files/models/   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”œâ”€â”€ gemma-3-1b-it-q4_0.gguf      (~700 MB)         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”œâ”€â”€ smolvlm2-2.2b-q4_k_s.gguf    (~800 MB)         â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€ smolvlm2-mmproj-f16.gguf     (~200 MB)         â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â”‚                    âš¡ Phone's CPU/GPU                            â”‚
â”‚                    Runs AI inference locally                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

            âŒ NO INTERNET NEEDED AFTER MODEL DOWNLOAD
            âŒ NO SERVER REQUIRED  
            âŒ NO API CALLS
            âŒ NO OLLAMA
```

---

## ğŸ“¥ Model Download Options

### Option A: In-App Download (Recommended for Production)

**User Experience:**
1. User installs app from Play Store (~50 MB)
2. Opens app for the first time
3. Sees "Download AI Models" screen
4. Downloads models over WiFi (~700 MB - 2 GB)
5. From now on, 100% offline!

```tsx
// Example download screen UI
<View>
  <Text>Download AI Models</Text>
  <Text>Required for offline learning</Text>
  
  <ModelDownloadCard 
    name="Gemma 3 (Text AI)" 
    size="700 MB" 
    onDownload={downloadTextModel}
  />
  
  <Text>âš ï¸ Connect to WiFi for best experience</Text>
</View>
```

### Option B: Manual Download (For Development/Testing)

Download files directly to your computer, then copy to device:

---

## ğŸ¯ Step-by-Step: Download Gemma 3 Model

### Method 1: PowerShell (Windows)

```powershell
# Navigate to models folder
cd d:\Hackathon\Eduthon\masterji\assets\models

# Download Gemma 3 1B (Q4 quantized) - ~700 MB
# This is the correct direct download URL:
Invoke-WebRequest `
  -Uri "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf/resolve/main/gemma-3-1b-it-q4_0.gguf" `
  -OutFile "gemma-3-1b-it-q4_0.gguf"
```

### Method 2: Browser Download

1. Go to: https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf/tree/main
2. Click on the file `gemma-3-1b-it-q4_0.gguf`
3. Click the "Download" button
4. Move the file to `assets/models/` folder

### Method 3: Curl (macOS/Linux)

```bash
cd assets/models
curl -L -o gemma-3-1b-it-q4_0.gguf \
  "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf/resolve/main/gemma-3-1b-it-q4_0.gguf"
```

---

## ğŸ“¦ Model Files We Need

| Model | Purpose | Size | Required |
|-------|---------|------|----------|
| `gemma-3-1b-it-q4_0.gguf` | Text generation, Q&A | ~700 MB | âœ… Yes |
| `smolvlm2-2.2b-instruct-q4_k_s.gguf` | Vision, OCR | ~800 MB | For scanning |
| `smolvlm2-2.2b-instruct-mmproj-f16.gguf` | Vision projector | ~200 MB | For scanning |

**For Hackathon MVP:** Just download Gemma 3 (~700 MB) - you can do text AI without vision.

---

## ğŸ”§ How to Build & Run

### For Development/Testing:

Since llama.rn requires native code, you CANNOT use Expo Go. You need a development build:

```bash
# 1. Install expo-dev-client
npx expo install expo-dev-client

# 2. Create a development build using EAS
eas build --profile development --platform android

# 3. OR build locally (requires Android Studio)
npx expo prebuild
npx expo run:android
```

### What the Build Does:

```
expo prebuild
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generates native Android/iOS projects   â”‚
â”‚ with llama.rn native code included      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
npx expo run:android
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Builds APK with:                        â”‚
â”‚ â€¢ React Native code                     â”‚
â”‚ â€¢ llama.cpp native library              â”‚
â”‚ â€¢ All your TypeScript code              â”‚
â”‚                                         â”‚
â”‚ APK size: ~50-80 MB                     â”‚
â”‚ (Models NOT included)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“± User Flow When Using Your App

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1ï¸âƒ£ USER INSTALLS APP                    â”‚
â”‚    From Play Store or APK file          â”‚
â”‚    Size: ~50-80 MB                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2ï¸âƒ£ FIRST LAUNCH                         â”‚
â”‚    App checks if models exist           â”‚
â”‚    Models NOT found â†’ Show download UI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3ï¸âƒ£ MODEL DOWNLOAD SCREEN               â”‚
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“¦ Download AI Models           â”‚   â”‚
â”‚  â”‚                                  â”‚   â”‚
â”‚  â”‚ To enable offline learning,     â”‚   â”‚
â”‚  â”‚ download the AI models (700 MB) â”‚   â”‚
â”‚  â”‚                                  â”‚   â”‚
â”‚  â”‚ âš ï¸ Connect to WiFi              â”‚   â”‚
â”‚  â”‚                                  â”‚   â”‚
â”‚  â”‚ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 45%          â”‚   â”‚
â”‚  â”‚                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4ï¸âƒ£ MODELS STORED LOCALLY               â”‚
â”‚                                         â”‚
â”‚    /storage/emulated/0/Android/data/   â”‚
â”‚    com.edulite.masterji/files/models/  â”‚
â”‚    â””â”€â”€ gemma-3-1b-it-q4_0.gguf (700MB) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5ï¸âƒ£ 100% OFFLINE FOREVER!               â”‚
â”‚                                         â”‚
â”‚    â€¢ No internet needed                 â”‚
â”‚    â€¢ AI runs on phone's CPU/GPU         â”‚
â”‚    â€¢ Fast responses (3-15 seconds)      â”‚
â”‚    â€¢ Complete privacy                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Why This Approach?

### Pros:
âœ… **Small app size** - Only 50-80 MB to download from app store  
âœ… **User choice** - Users can choose which models to download  
âœ… **Updatable models** - Can push new models without app update  
âœ… **Storage efficient** - Users can delete models to free space  
âœ… **Works on older devices** - Smaller model options available

### Cons:
âŒ Requires WiFi for initial model download  
âŒ Large download after install (700 MB - 2 GB)  
âŒ Some users may not complete download

### Alternative (Bundle Models):
âŒ App would be 2+ GB - too large for app stores  
âŒ Users forced to download entire model even if they don't need it  
âŒ Updates would require re-downloading everything

---

## ğŸ® Comparison with Other Approaches

| Approach | App Size | Offline? | Speed | Privacy |
|----------|----------|----------|-------|---------|
| **llama.rn (Ours)** | 50 MB + 700 MB download | âœ… 100% | Fast | âœ… Full |
| Ollama (Server) | Small | âŒ Needs server | Very Fast | âŒ Data leaves device |
| Cloud API (OpenAI) | Tiny | âŒ Internet required | Varies | âŒ Data sent to cloud |
| Bundled Model | 2+ GB | âœ… 100% | Fast | âœ… Full |

---

## ğŸš€ Quick Start for Hackathon

### Step 1: Download Model (One-Time)
```powershell
cd d:\Hackathon\Eduthon\masterji\assets\models

Invoke-WebRequest `
  -Uri "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf/resolve/main/gemma-3-1b-it-q4_0.gguf" `
  -OutFile "gemma-3-1b-it-q4_0.gguf"
```

### Step 2: Create Development Build
```bash
npx expo install expo-dev-client
npx expo prebuild
npx expo run:android
```

### Step 3: Test AI Features
The app will load the model from `assets/models/` and run AI inference locally!

---

## ğŸ“‹ Summary

**Key Points:**
1. **No Ollama needed** - llama.rn runs directly on device
2. **Models downloaded separately** - Not bundled in app
3. **100% offline after download** - No internet required
4. **Privacy-first** - All data stays on device
5. **Development build required** - Can't use Expo Go

**File Locations:**
- Models stored at: `DocumentDirectoryPath/models/`
- Typical path: `/data/data/com.edulite.masterji/files/models/`
- Size: 700 MB - 2 GB total
